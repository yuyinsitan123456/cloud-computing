package edu.illinois.cs.cogcomp.twitter.lbj;

import edu.illinois.cs.cogcomp.twitter.datastructures.Tweet;
import edu.illinois.cs.cogcomp.twitter.TweetReader;
import java.util.List;

/* This particular function simply produces "bag of words" features. */
discrete% WordFeatures(Tweet t) <- {
    List words = t.getWords();
    for (int i = 0; i < words.size(); i++)
        sense words.get(i);
}

/* This function produces bigram features. Notice how the argument to "sense" has changed. */
discrete% BigramFeatures(Tweet t) <- {
    List words = t.getWords();
    for (int i = 0; i < words.size() - 1; i++)
        sense words.get(i)+"-"+words.get(i+1);
}

/* In the current training corpus a tweet can only have a positive or negative sentiment. */
discrete{"positive", "negative"} Label(Tweet t) <- { return t.getSentimentLabel(); }

/**
 * A simple classifier that uses a tweet's text as its only source of features.
 * Can be expanded to include all the metadata in Twitter's JSON.
 */
discrete SentimentClassifier(Tweet t) <-
	learn Label
    using WordFeatures, BigramFeatures

    // Use a TweetReader to load the training data
    from new TweetReader("data/train50k.csv.gz")

    5 rounds

//     Different classifier options:
//     with new NaiveBayes()
//     with new SupportVectorMachine()
//     with new AdaBoost()
//     with new PassiveAggressive()
//     with new SparseConfidenceWeighted()
     with new SparseNetworkLearner()
//     with SparseAveragedPerceptron {
//       learningRate = 0.1 ;
//       thickness = 3.5;
//     }

    // Use a TweetReader to load the testing data
    testFrom new TweetReader("data/test.csv.gz")

    // Give an update every 10000 tweets
    progressOutput 10000
 end